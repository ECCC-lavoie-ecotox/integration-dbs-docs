[
  {
    "objectID": "itgr_tbl_sites.html",
    "href": "itgr_tbl_sites.html",
    "title": "Recensement des sites",
    "section": "",
    "text": "On dispose d’une liste de référence des sites avec leurs localisations à cet emplacement Z:\\07-Données BD\\intermediate_files\\sites_tp20_et_dbs_list_24042024.xlsx.\nCe fichier est le fruit d’une consolidation manuelle entre les sites documentés dans les onglets “Metadata - entêtes et notes” de plusieurs bases de données du PASL et le fichier TP-20, disposant de liste de choix pré-établie.\nOn charge cette table des sites en mémoire.\n\nsites_tp20_dbs &lt;- readxl::read_excel(\"Z:/07-Données BD/intermediate_files/sites_tp20_et_dbs_list_24042024.xlsx\")\n\nOn commence par extraire la liste des sites identifiés dans toutes les bases de données.\n\nsource(\"src/itgr_measurements.R\")\nsites &lt;- itgr_measurements() |&gt;\n    dplyr::select(location = Location, source) |&gt;\n    dplyr::distinct()\n\nOn effectue un fuzzy join en se basant sur le nom du site.\n\nsites_with_locations &lt;- fuzzyjoin::stringdist_left_join(\n    sites, \n    sites_tp20_dbs,\n    method = \"lv\"\n) |&gt; dplyr::distinct()\n\nJoining by: \"location\"\n\n# writexl::write_xlsx(sites_with_locations, \"Z:/07-Données BD/intermediate_files/site_locations_29042024.xlsx\")\n\nAprès une consolidation manuelle effectuer dans le fichier Z:/07-Données BD/intermediate_files/site_locations_29042024.xlsx.\nOn peut à présent cartographier les sites pour lesquelles nous disposons d’une localisation.\n\nsites &lt;- readxl::read_excel(\"Z:/07-Données BD/intermediate_files/site_locations_29042024.xlsx\")\n\nlibrary(sf)\n\nWarning: package 'sf' was built under R version 4.3.3\n\n\nLinking to GEOS 3.11.2, GDAL 3.8.2, PROJ 9.3.1; sf_use_s2() is TRUE\n\nsites_sf &lt;- sites |&gt;\n    dplyr::filter(!is.na(lat) | !is.na(lon)) |&gt; \n    sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\n\nmapview::mapview(sites_sf)",
    "crumbs": [
      "Data integration [FR]",
      "Recensement des sites"
    ]
  },
  {
    "objectID": "itgr_tbl_measurements.html",
    "href": "itgr_tbl_measurements.html",
    "title": "Description des contaminants",
    "section": "",
    "text": "On cherche à obtenir une liste exhaustive des contaminants mesurés chez quatre espèces impliquées dans le PASL.\n\nsource(\"src/itgr_measurements.R\")\ncontaminants &lt;- itgr_measurements()\n\n\n\nCertains noms de composées divergent entre les différents classeurs de données (espèces)\ndups_contaminants &lt;- contaminants |&gt; \n    dplyr::group_by(conpound_family, variable) |&gt;\n    dplyr::arrange(desc(variable)) |&gt;\n    dplyr::count()\n\nreactable::reactable(dups_contaminants)\n\n\nAtelier 1: Jouer a pareil, pas pareil, pour consolider la nomenclature des contaminants\n\n\n\ndups_sites &lt;- contaminants |&gt; \n    dplyr::group_by(Location) |&gt;\n    dplyr::count()\n\nreactable::reactable(dups_sites)\n\n\nAtelier 2: Jouer a pareil, pas pareil, pour consolider la nomenclature des sites\n\n\n\nOn applique la transformation avec la fonction toxbox::uncensored().\n\ncontaminants_uncensored &lt;- contaminants |&gt; \n    toxbox::uncensored(cols = \"value\", keep_cens = TRUE)\n\nWarning: There was 1 warning in `dplyr::mutate()`.\nℹ In argument: `dplyr::across(tidyselect::all_of(cols), remove_cens)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nIsolation des valeurs NA’s pour comprendre quelles sont les mesures qui ne peuvent pas être transformé en valeur numérique.\n\n\n\ntable(is.na(contaminants_uncensored$value))\n\n\nFALSE  TRUE \n35185  1271 \n\n\n\n\n\n\ncontaminants_uncensored |&gt; \n    dplyr::filter(is.na(value)) |&gt;\n    dplyr::group_by(source, conpound_family) |&gt;\n    dplyr::count() |&gt;\n    dplyr::arrange(source) |&gt;\n    reactable::reactable()\n\n\n\n\n\n\n\n\nTODO: A compléter ici, marche pas\n\ncontaminants |&gt; \n    dplyr::filter(stringr::str_detect(stringr::str_trim(value), \"[:alpha:]\")) |&gt;\n    as.data.frame() |&gt;\n    reactable::reactable()",
    "crumbs": [
      "Data integration [FR]",
      "Description des contaminants"
    ]
  },
  {
    "objectID": "itgr_tbl_measurements.html#otenir-une-liste-exhaustive-des-contaminants",
    "href": "itgr_tbl_measurements.html#otenir-une-liste-exhaustive-des-contaminants",
    "title": "Description des contaminants",
    "section": "",
    "text": "On cherche à obtenir une liste exhaustive des contaminants mesurés chez quatre espèces impliquées dans le PASL.\n\nsource(\"src/itgr_measurements.R\")\ncontaminants &lt;- itgr_measurements()\n\n\n\nCertains noms de composées divergent entre les différents classeurs de données (espèces)\ndups_contaminants &lt;- contaminants |&gt; \n    dplyr::group_by(conpound_family, variable) |&gt;\n    dplyr::arrange(desc(variable)) |&gt;\n    dplyr::count()\n\nreactable::reactable(dups_contaminants)\n\n\nAtelier 1: Jouer a pareil, pas pareil, pour consolider la nomenclature des contaminants\n\n\n\ndups_sites &lt;- contaminants |&gt; \n    dplyr::group_by(Location) |&gt;\n    dplyr::count()\n\nreactable::reactable(dups_sites)\n\n\nAtelier 2: Jouer a pareil, pas pareil, pour consolider la nomenclature des sites\n\n\n\nOn applique la transformation avec la fonction toxbox::uncensored().\n\ncontaminants_uncensored &lt;- contaminants |&gt; \n    toxbox::uncensored(cols = \"value\", keep_cens = TRUE)\n\nWarning: There was 1 warning in `dplyr::mutate()`.\nℹ In argument: `dplyr::across(tidyselect::all_of(cols), remove_cens)`.\nCaused by warning:\n! NAs introduced by coercion\n\n\nIsolation des valeurs NA’s pour comprendre quelles sont les mesures qui ne peuvent pas être transformé en valeur numérique.\n\n\n\ntable(is.na(contaminants_uncensored$value))\n\n\nFALSE  TRUE \n35185  1271 \n\n\n\n\n\n\ncontaminants_uncensored |&gt; \n    dplyr::filter(is.na(value)) |&gt;\n    dplyr::group_by(source, conpound_family) |&gt;\n    dplyr::count() |&gt;\n    dplyr::arrange(source) |&gt;\n    reactable::reactable()\n\n\n\n\n\n\n\n\nTODO: A compléter ici, marche pas\n\ncontaminants |&gt; \n    dplyr::filter(stringr::str_detect(stringr::str_trim(value), \"[:alpha:]\")) |&gt;\n    as.data.frame() |&gt;\n    reactable::reactable()",
    "crumbs": [
      "Data integration [FR]",
      "Description des contaminants"
    ]
  },
  {
    "objectID": "itgr_n_measurements.html",
    "href": "itgr_n_measurements.html",
    "title": "Déterminer la taille des échantillons par site",
    "section": "",
    "text": "On compte le nombre de mesures pour chaque combinaison.\nsource(\"src/itgr_measurements.R\")\ncontaminants &lt;- itgr_measurements()\n\ndata_count &lt;- contaminants |&gt; \n    dplyr::mutate(Year = as.integer(Year)) |&gt;\n    toxbox::uncensored(cols = \"value\", keep_cens = TRUE) |&gt;\n    dplyr::group_by(Location, Year, Species, conpound_family, variable) |&gt;\n    dplyr::summarise(n = dplyr::n(), n_censored = sum(value_censored))\nWarning: There was 1 warning in `dplyr::mutate()`.\nℹ In argument: `dplyr::across(tidyselect::all_of(cols), remove_cens)`.\nCaused by warning:\n! NAs introduced by coercion\n`summarise()` has grouped output by 'Location', 'Year', 'Species',\n'conpound_family'. You can override using the `.groups` argument.\n\ndata_count |&gt;\n    reactable::reactable()\n\n\n\n\n\n\nCriteria 1. On retire les sites pour lesquelles, il y a une seule année de collecte (impossibilité de calibrer un modèle de tendance temporelle).\nVoici la liste des sites pour lesquelles, on a une seule année de mesure\ncrit1 &lt;- contaminants |&gt; \n    dplyr::select(Location, Year) |&gt;\n    dplyr::distinct() |&gt;\n    dplyr::group_by(Location) |&gt;\n    dplyr::count() |&gt;\n    dplyr::filter(n == 1) |&gt;\n    dplyr::pull(Location)\n\ncat(paste(\"*\", crit1), sep=\"\\n\")\n\nArchipel de Mingan (approximative location)\nBeauharnois\nBetchouanes\nBonaventure\nDeslauriers\nEscuminac\nGros Pot\nIle Beauséjour\nIle Bellechasse\nIle Bienville\nIle Blanche\nIle Dodens\nIle Dowker\nIle Nue\nIle Saint-Barnabé\nIle a Bouleau de Terre\nIle aux Pommes\nIle de la Madeleine\nIle de la Mine\nIle du Petit Caoui\nIle du Petit Caouis\nIle à Calculot des Betchouanes\nIles aux Loups Marins\nIles de la Madeleine\nIlets Boisés\nIlets De Quen\nKamouraska\nKukuministuk (Caye à Cochons)\nLac Bleu\nLac Evans\nLac Saint-Bernard\nLac St-Pierre\nLac à la Carpe\nLong Island\nMiller island\nMissipinuk (Grosse Romaine)\nPetit Lac Jacques Cartier\nPetite Ile Ste-Geneviève\nPointe Saint-Pancrace\nPrairie du Castor\nRiviere George\n\nOn retire ces sites pour l’étude de la taille de l’échantillon\n\ndata_count &lt;- data_count |&gt;\n    dplyr::filter(!(Location %in% crit1)) |&gt;\n    dplyr::ungroup()\n\n\n\nSite Battures aux Loups Marins\n\n\n\nSite Bonaventure Island\n\n\n\nSite Grande Ile\n\n\n\nSite Ile Carillon\n\n\n\nSite Ile Dickerson\n\n\n\nSite Ile Eaton\n\n\n\nSite Ile Laval\n\n\n\nSite Ile Manowin\n\n\n\nSite Ile Matane\n\n\n\nSite Ile Saint-Bernard\n\n\n\nSite Ile Steamboat\n\n\n\nSite Ile Villemomble\n\n\n\nSite Ile aux Basques\n\n\n\nSite Ile aux Herons\n\n\n\nSite Ile aux Hérons\n\n\n\nSite Ile aux Oeufs\n\n\n\nSite Ile de Carillon\n\n\n\nSite Ile de la Corneille\n\n\n\nSite Ile du Bic\n\n\n\nSite Ile du Corossol\n\n\n\nSite Iles Sainte-Marie\n\n\n\nSite Maria\n\n\n\nSite Petit lac Jacques-Cartier\n\n\n\nSite Refuge Watshishou\n\n\n\nSite Yamachiche",
    "crumbs": [
      "Data integration [FR]",
      "Déterminer la taille des échantillons par site"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Purpose of this documentation",
    "section": "",
    "text": "Raphael Lavoie’s laboratory is working on integrating data from contaminant measurements on biological matrices for a study area covering the Estuary and Gulf of St. Lawrence.\nThe first section of this documentation focuses on the database structure and reviews the content of each field present in the database. The second section (in French) deals with the integration work, which requires several steps of data validation and consolidation. It also includes the code to generate some exploratory figures to better understand the data produced by this integration.",
    "crumbs": [
      "Introduction",
      "Purpose of this documentation"
    ]
  },
  {
    "objectID": "db_schema.html#database-creation",
    "href": "db_schema.html#database-creation",
    "title": "Database structure",
    "section": "Database creation",
    "text": "Database creation\nInstall the following dependancies. Packages DBI and RSQlite are R packages proving functions to connect and execute SQL instructions such as table creation.\n\ninstall.packages(c(\"RSQLite\", \"DBI\"))\n\nWe first create or connect to an existing sqlite database.\n\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"./contaminants-rlavoie-eccc.sqlite\")\n\nWe then send all the SQL instructions stored in sql/db_create_ddl.sql file with DBI::dbExecute().\n\ndb_ddl_sql &lt;- strsplit(paste(readLines(\"sql/db_create_ddl.sql\"), collapse = \"\\n\"), \";\\n\")[[1]]\npurrr::walk(db_ddl_sql, \\(x) DBI::dbExecute(con, x))",
    "crumbs": [
      "Database",
      "Database structure"
    ]
  },
  {
    "objectID": "db_schema.html#sql-script",
    "href": "db_schema.html#sql-script",
    "title": "Database structure",
    "section": "SQL script",
    "text": "SQL script\nHere is the content of the SQL instructions file:\nPRAGMA foreign_keys = ON;\n\nDROP TABLE IF EXISTS lab_field_sample;\n\nDROP TABLE IF EXISTS lab_measurement;\n\nDROP TABLE IF EXISTS lab_sample;\n\nDROP TABLE IF EXISTS field_sample;\n\nDROP TABLE IF EXISTS capture;\n\nDROP TABLE IF EXISTS species;\n\nDROP TABLE IF EXISTS sites;\n\nDROP TABLE IF EXISTS report;\n\nDROP TABLE IF EXISTS project;\n\nDROP TABLE IF EXISTS individual;\n\nDROP TABLE IF EXISTS analyte;\n\n\n-- analyte definition\n\nCREATE TABLE analyte -- Create table which contains analyte description provided by the lab\n(\n    id_analyte TEXT PRIMARY KEY,\n    name TEXT NOT NULL,\n    other_name TEXT,\n    short_name TEXT, \n    unit TEXT,\n    family TEXT,\n    casid TEXT,\n    pubcid INTEGER,\n    note_analyte TEXT,\n    is_dry_weight BOOLEAN CHECK (is_dry_weight IN (0, 1)),\n    on_isolated_lipid BOOLEAN CHECK (on_isolated_lipid IN (0, 1))\n);\n\n\n-- individual definition\n\nCREATE TABLE individual -- Create a new table which document informations on individual\n(\n    id_individual TEXT NOT NULL PRIMARY KEY,\n    active_band TEXT,\n    sex TEXT\n);\n\n\n-- lab_sample definition\n\nCREATE TABLE lab_sample -- Create a new table which document all lab sample\n-- Lab sample could be one or multiple field sample pooled\n(\n    id_lab_sample TEXT NOT NULL PRIMARY KEY,\n    note_lab_sample TEXT\n);\n\n\n-- project definition\n\nCREATE TABLE project -- Create table which contains project metadata description in association with field and/or lab samples\n(\n    id_project TEXT PRIMARY KEY,\n    title TEXT,\n    organization TEXT,\n    investigator TEXT,\n    data_manager TEXT,\n    email_investigator TEXT,\n    email_data_manager TEXT,\n    description TEXT\n);\n\n\n-- sites definition\n\nCREATE TABLE sites -- Create reference table for each site location\n(\n    id_site TEXT PRIMARY KEY,\n    name_en TEXT,\n    province TEXT NOT NULL,\n    lat FLOAT,\n    lon FLOAT,\n    srid INTEGER\n);\n\n\n-- species definition\n\nCREATE TABLE species -- Create a reference table for each species involved in study\n(\n    id_species TEXT PRIMARY KEY,\n    organism TEXT NOT NULL,\n    genus TEXT NOT NULL,\n    species TEXT NOT NULL,\n    vernacular_fr TEXT NOT NULL,\n    vernacular_en TEXT NOT NULL\n);\n\n\n-- capture definition\n\nCREATE TABLE capture -- Create a new table which document species capture event\n(\n    id_capture TEXT NOT NULL,\n    id_individual TEXT NOT NULL,\n    date TEXT NOT NULL,\n    time_capture TEXT NOT NULL,\n    section TEXT,\n    nest_id TEXT,\n    nest_content TEXT,\n    age TEXT,\n    estimation_sex TEXT,\n    previous_band TEXT,\n    plastic_band TEXT,\n    previous_plastic_band TEXT,\n    blood_volume_ml FLOAT,\n    egg_collect BOOLEAN,\n    feather_p8 TEXT,\n    avian_flue BOOLEAN,\n    mass FLOAT,\n    mass_g TEXT,\n    head_length_mm FLOAT,   \n    culmen_length_mm FLOAT, \n    beak_thickness TEXT,    \n    p9_length_mm FLOAT, \n    tarsus_length_mm FLOAT,     \n    half_span_mm FLOAT,     \n    tracker_removal TEXT,   \n    id_tracker_removal TEXT,    \n    tracker_deployment TEXT,    \n    id_tracker_deployment TEXT, \n    activation_time TEXT,\n    time_euthanasia TEXT,\n    mortality BOOLEAN,  \n    note_capture TEXT,\n    UNIQUE(id_capture, id_individual) ON CONFLICT ROLLBACK,\n    FOREIGN KEY(id_individual) REFERENCES individual(id_individual) ON UPDATE CASCADE\n);\n\n\n-- field_sample definition\n\nCREATE TABLE \"field_sample\" -- Create a new table which document collected field samples\n(\n    id_field_sample TEXT NOT NULL PRIMARY KEY,\n    id_capture TEXT,\n    collection_date TEXT,\n    id_site TEXT NOT NULL,\n    id_species TEXT NOT NULL,\n    age TEXT,\n    tissue TEXT,\n    FOREIGN KEY(id_site) REFERENCES sites(id_site) ON UPDATE CASCADE,\n    FOREIGN KEY(id_species) REFERENCES species(id_species) ON UPDATE CASCADE,\n    FOREIGN KEY(id_capture) REFERENCES capture(id_capture) ON UPDATE CASCADE\n);\n\n\n-- lab_field_sample definition\n\nCREATE TABLE lab_field_sample -- Create a new table which document all lab sample\n-- Lab sample could be one or multiple field sample pooled\n(\n    id_lab_sample TEXT NOT NULL,\n    id_field_sample TEXT,\n    note_lab_field_sample TEXT,\n    UNIQUE(id_lab_sample, id_field_sample) ON CONFLICT ROLLBACK,\n    FOREIGN KEY(id_field_sample) REFERENCES field_sample(id_field_sample) ON UPDATE CASCADE,\n    FOREIGN KEY(id_lab_sample) REFERENCES lab_sample(id_lab_sample) ON UPDATE CASCADE\n);\n\n\n-- report definition\n\nCREATE TABLE report -- Create table which contains project metadata description in association with field and/or lab samples\n(\n    id_report TEXT NOT NULL PRIMARY KEY,\n    id_project TEXT,\n    report_date TEXT,\n    report_access_path TEXT,\n    FOREIGN KEY(id_project) REFERENCES project(id_project) ON UPDATE CASCADE\n);\n\n\n-- lab_measurement definition\n\nCREATE TABLE \"lab_measurement\" -- Create a new table which contains lab measurements\n(\n    id_lab_sample TEXT NOT NULL,\n    id_analyte TEXT NOT NULL,\n    value FLOAT NOT NULL,\n    is_censored BOOLEAN CHECK (is_censored IN (0, 1)) DEFAULT 0,\n    percent_lipid FLOAT,\n    percent_moisture FLOAT,\n    note_lab_measurement TEXT, id_report text,\n    UNIQUE (id_lab_sample, id_analyte) ON CONFLICT ROLLBACK,\n    FOREIGN KEY(id_lab_sample) REFERENCES lab_sample(id_lab_sample) ON UPDATE CASCADE,\n    FOREIGN KEY(id_analyte) REFERENCES analyte(id_analyte) ON UPDATE CASCADE,\n    FOREIGN KEY (id_report) REFERENCES report(id_report) ON UPDATE CASCADE\n);",
    "crumbs": [
      "Database",
      "Database structure"
    ]
  },
  {
    "objectID": "db_injections_example.html",
    "href": "db_injections_example.html",
    "title": "Lab results importation example",
    "section": "",
    "text": "To maintain the referential integrity of the data, the data injection must be done in a certain order. For example, all sites must be entered first before the associated samples can be declared.\nHere is the expected injection order according to the database structure:\n\nProjects\nReports\nSites\nSpecies\nField samples\nLab samples\nLab measurement\n\nAll the data intended to populate the tables was consolidated during the previous steps. We will now proceed with importing them into the database.\nThis document allows the import of laboratory measurements for the MET-Thg-23-19 report.",
    "crumbs": [
      "Database",
      "Lab results importation example"
    ]
  },
  {
    "objectID": "db_injections_example.html#data-importation-procedure",
    "href": "db_injections_example.html#data-importation-procedure",
    "title": "Lab results importation example",
    "section": "",
    "text": "To maintain the referential integrity of the data, the data injection must be done in a certain order. For example, all sites must be entered first before the associated samples can be declared.\nHere is the expected injection order according to the database structure:\n\nProjects\nReports\nSites\nSpecies\nField samples\nLab samples\nLab measurement\n\nAll the data intended to populate the tables was consolidated during the previous steps. We will now proceed with importing them into the database.\nThis document allows the import of laboratory measurements for the MET-Thg-23-19 report.",
    "crumbs": [
      "Database",
      "Lab results importation example"
    ]
  },
  {
    "objectID": "db_injections_example.html#database-backup",
    "href": "db_injections_example.html#database-backup",
    "title": "Lab results importation example",
    "section": "Database backup",
    "text": "Database backup\nThe first step is to ensure that we can restore the database if the import introduces errors into the database.\n\ndb_path &lt;- \"Z:/07-Données BD/Database/contaminants-rlavoie-eccc.sqlite\"\n\ndb_bak &lt;- stringr::str_replace(\n    db_path, \n    pattern = \".sqlite\", \n    replacement = glue::glue(\"-{format(Sys.Date(), '%Y%m%d')}.bak.sqlite\")\n)\n\nfile.copy(db_path, db_bak)",
    "crumbs": [
      "Database",
      "Lab results importation example"
    ]
  },
  {
    "objectID": "db_injections_example.html#loading-library-dependancy",
    "href": "db_injections_example.html#loading-library-dependancy",
    "title": "Lab results importation example",
    "section": "Loading library dependancy",
    "text": "Loading library dependancy\n\nif(!require(devtools)) install.packages(\"devtools\")\nif(!require(toxbox)) devtools::install_github(\"ECCC-lavoie-ecotox/toxbox.git\")",
    "crumbs": [
      "Database",
      "Lab results importation example"
    ]
  },
  {
    "objectID": "db_injections_example.html#loading-the-data-report-within-the-r-environment",
    "href": "db_injections_example.html#loading-the-data-report-within-the-r-environment",
    "title": "Lab results importation example",
    "section": "Loading the data report within the R environment",
    "text": "Loading the data report within the R environment\n\ntarget_path_lab_results &lt;- \"Z:/03-Labo/Results Reports/À entrer dans la BD/MET-THg-23-19 - RALA01-2023.xlsx\"\n\n# Informations sur les échantillons\nsampleInfoLab &lt;- readxl::read_xlsx(target_path_lab_results, \"SampleInfo\")\n\n# Informations sur les mesures\nmeasurementsLab &lt;- readxl::read_xlsx(target_path_lab_results, \"SampleData\")",
    "crumbs": [
      "Database",
      "Lab results importation example"
    ]
  },
  {
    "objectID": "db_injections_example.html#initialize-the-database-connection",
    "href": "db_injections_example.html#initialize-the-database-connection",
    "title": "Lab results importation example",
    "section": "Initialize the database connection",
    "text": "Initialize the database connection\n\ncon &lt;- toxbox::init_con()",
    "crumbs": [
      "Database",
      "Lab results importation example"
    ]
  },
  {
    "objectID": "db_injections_example.html#data-injection",
    "href": "db_injections_example.html#data-injection",
    "title": "Lab results importation example",
    "section": "Data injection",
    "text": "Data injection\n\nReport and project metadata importation\n\nreport &lt;- data.frame(\n    id_report = \"MET-Thg-23-19\",\n    id_project = \"RALA01-2023\",\n    report_date = \"2024-07-31\",\n    report_access_path = stringr::str_replace(\"Z:/03-Labo/Results Reports/À entrer dans la BD/MET-THg-23-19 - RALA01-2023.xlsx\", \"À entrer dans la BD\", \"Saisie dans la BD\")\n)\n\nWe first validate if the project ID already exists in the database.\n\ntoxbox::search_tbl(con, \"project\", id_project = \"RALA01-2023\")\n\nIt already exists in the database. Therefore, we can import the report metadata that will be attached to this project.\n\nDBI::dbWriteTable(con, \"report\", report, append = TRUE)\n\n\n\nData preparation\n\nGather field sample informations\n\nfield_sample &lt;- sampleInfoLab |&gt; dplyr::select(\n    id_lab_sample = SampleID,\n    id_field_sample = ClientID,\n    collection_date = CollectionDate,\n    id_site = Location,\n    id_species = Species,\n    tissue = Tissue,\n    age = Age\n)\n\n\n\nGather lab meaurements\n\nmeasurements &lt;- measurementsLab |&gt; dplyr::select(\n    id_lab_sample = SampleID,\n    id_field_sample = ClientID,\n    pmoisture = `% Moisture`,\n    value = `Total Mercury (µg/g (dry))`\n) |&gt; dplyr::mutate(\n    id_analyte = \"thg_dw\"\n)\n\n\n\n\nSite importation\nWe must establish correspondance with existing sites in database and create the ones that are not already present in the database.\nFirst, we isolate the sites present in the results sent by the laboratory.\n\n(sitesLab &lt;- dplyr::distinct(sampleInfoLab, Location, Latitude, Longitude))\n\nWe search the database for the existing sites using keywords.\n\nbetchouanes_site_db &lt;- toxbox::search_tbl(con, \"sites\", id_site = \"%betchouanes%\")\nmingan_site_db &lt;- toxbox::search_tbl(con, \"sites\", id_site = \"%mingan%\")\n\nAfter searching the database for sites, we can see that the Betchouanes site is already recorded in the database, but the Longue-Pointe-de-Mingan site is not. Therefore, we add this site.\n\nadd_site &lt;- sitesLab |&gt; \n    dplyr::filter(Location == \"Longue-Pointe-de-Mingan\") |&gt; \n    dplyr::select(\n        id_site = Location,\n        lat = Latitude,\n        lon = Longitude\n    ) |&gt;\n    dplyr::mutate(\n        province = 'Québec',\n        srid = 4326\n    )\n\nDBI::dbWriteTable(con, \"sites\", add_site, append = TRUE)\n\nWe verify that the site has indeed been added to the database.\n\ntoxbox::search_tbl(con, \"sites\", id_site = \"Longue-Pointe-de-Mingan\")\n\n\nfield_sample &lt;- field_sample |&gt;\n    dplyr::mutate(\n        id_site = dplyr::case_when(\n            stringr::str_detect(id_site, \"Ile a Calculot des Betchouanes\") == TRUE ~ betchouanes_site_db$id_site,\n            .default = id_site\n        )\n    )",
    "crumbs": [
      "Database",
      "Lab results importation example"
    ]
  },
  {
    "objectID": "db_injections_example.html#species-importation",
    "href": "db_injections_example.html#species-importation",
    "title": "Lab results importation example",
    "section": "Species importation",
    "text": "Species importation\nWe list the species, starting with those present in the laboratory results.\n\nunique(field_sample$id_species)\n\nWe compare it with the list of species present in the database.\n\nDBI::dbReadTable(con, \"species\")\n\nWe declare a data.frame with the missing species\n\nnew_species &lt;- tibble::tribble(\n   ~org_species, ~id_species, ~organism, ~genus, ~species, ~vernacular_fr, ~vernacular_en,\n  \"Alose sp.\", \"SHSP\", \"Fish\", \"Alosa\",   \"Alosa sp.\", \"Alose\", \"Shad\",\n  \"Gadidae sp.\", \"COSP\", \"Fish\", \"Gadidae\", \"Gadidae sp.\", \"Morue\", \"Cod\",\n  \"Lompenie tachete\", \"DASH\", \"Fish\", \"Gadidae\", \"Leptoclinus maculatus\", \"Lompénie tachetée\", \"Daubed shanny\"\n)\n\nWe add those missing species in the database\n\nDBI::dbWriteTable(con, \"species\", dplyr::select(new_species, -org_species)\n, append = TRUE)\n\nWe visually confirm that the new species are indeed present in the database.\n\nDBI::dbReadTable(con, \"species\")\n\nWe match the species codes from the laboratory report with those in the database.\n\nfield_sample &lt;- field_sample |&gt; dplyr::mutate(\n    id_species = dplyr::case_when(\n        id_species == \"Alose sp.\" ~ \"SHSP\",\n        id_species == \"Capelan\" ~ \"CAPE\",\n        id_species == \"Gadidae sp.\" ~ \"COSP\",\n        id_species == \"Lancon\" ~ \"SAND\",\n        id_species == \"Lompenie tachete\" ~ \"DASH\",\n        .default = NA\n    )\n) |&gt; dplyr::filter(!is.na(id_species))",
    "crumbs": [
      "Database",
      "Lab results importation example"
    ]
  },
  {
    "objectID": "db_injections_example.html#lab-measurements-injection",
    "href": "db_injections_example.html#lab-measurements-injection",
    "title": "Lab results importation example",
    "section": "Lab measurements injection",
    "text": "Lab measurements injection\nThe previous steps have updated the reference tables for sites and species.\nWe can now proceed to import the data on samples and measurements.\n\nField samples\n\ndplyr::select(field_sample, id_field_sample, collection_date, id_site, id_species, age, tissue) |&gt; \n    dplyr::distinct() |&gt; \n    (\\(data) DBI::dbWriteTable(con, \"field_sample\", data, append = TRUE))()\n\n\n\nLab samples\n\ndplyr::select(field_sample, id_lab_sample) |&gt; \n    dplyr::distinct() |&gt; \n    (\\(data) DBI::dbWriteTable(con, \"lab_sample\", data, append = TRUE))()\n\n\n\nLab field samples\nThis table links the laboratory samples with the field samples. This join table is necessary as lab samples can hold several field sample (often the case with eggs).\n\ndplyr::select(field_sample, id_lab_sample, id_field_sample) |&gt; \n    dplyr::distinct() |&gt; \n    (\\(data) DBI::dbWriteTable(con, \"lab_field_sample\", data, append = TRUE))()\n\n\n\nLab measurements\nFinaly, all the parent table (field_sample, lab_sample, lab_field_sample) have been recorded in the database. We can now import the lab measurements record. We have to manualy declare the MDL/LOD value in order to assess if the measurement value is cencored or not.\n\n# Set method detection limit\nMDL &lt;- 0.0001\n\ndplyr::select(measurements, id_lab_sample, id_analyte, value, percent_moisture = pmoisture) |&gt; \n    # The line below assess if the value is censored or not\n    dplyr::mutate(is_censored = ifelse(value &gt; MDL, 0, 1)) |&gt;\n    dplyr::mutate(id_report = report$id_report) |&gt; \n    (\\(data) DBI::dbWriteTable(con, \"lab_measurement\", data, append = TRUE))()",
    "crumbs": [
      "Database",
      "Lab results importation example"
    ]
  },
  {
    "objectID": "deploy.html",
    "href": "deploy.html",
    "title": "Contribute to this documentation",
    "section": "",
    "text": "To build this documentation locally, follow these steps.",
    "crumbs": [
      "Introduction",
      "Contribute to this documentation"
    ]
  },
  {
    "objectID": "deploy.html#get-documentation-source-code",
    "href": "deploy.html#get-documentation-source-code",
    "title": "Contribute to this documentation",
    "section": "Get documentation source code",
    "text": "Get documentation source code\nSteve - I will give a training on how to clone a git repository and push new edits to the documentation. In the meatime, if you’re already set to work with git and Rstudio, the repository URL is avaible at https://github.com/ECCC-lavoie-ecotox/integration-dbs-docs.",
    "crumbs": [
      "Introduction",
      "Contribute to this documentation"
    ]
  },
  {
    "objectID": "deploy.html#build-this-website",
    "href": "deploy.html#build-this-website",
    "title": "Contribute to this documentation",
    "section": "Build this website",
    "text": "Build this website\n# Serve the website in your browser\nquarto::quarto_preview()\nThis approach allows you to work on the documentation files in parallel. Each time a file is modified, the website is rebuilt to include the latest changes.",
    "crumbs": [
      "Introduction",
      "Contribute to this documentation"
    ]
  },
  {
    "objectID": "itgr_db_injections_rlavoie.html",
    "href": "itgr_db_injections_rlavoie.html",
    "title": "Injections des données",
    "section": "",
    "text": "source(\"src/itgr_measurements.R\")\nsource(\"src/itgr_samples_info.R\")",
    "crumbs": [
      "Data integration [FR]",
      "Injections des données"
    ]
  },
  {
    "objectID": "itgr_db_injections_rlavoie.html#chargements-des-scripts",
    "href": "itgr_db_injections_rlavoie.html#chargements-des-scripts",
    "title": "Injections des données",
    "section": "",
    "text": "source(\"src/itgr_measurements.R\")\nsource(\"src/itgr_samples_info.R\")",
    "crumbs": [
      "Data integration [FR]",
      "Injections des données"
    ]
  },
  {
    "objectID": "itgr_db_injections_rlavoie.html#création-de-la-base-de-données",
    "href": "itgr_db_injections_rlavoie.html#création-de-la-base-de-données",
    "title": "Injections des données",
    "section": "Création de la base de données",
    "text": "Création de la base de données\n\ncon &lt;- DBI::dbConnect(RSQLite::SQLite(), \"./contaminants-rlavoie-eccc.sqlite\")\ndb_ddl_sql &lt;- strsplit(paste(readLines(\"sql/db_create_ddl.sql\"), collapse = \"\\n\"), \";\\n\")[[1]]\npurrr::walk(db_ddl_sql, \\(x) DBI::dbExecute(con, x))",
    "crumbs": [
      "Data integration [FR]",
      "Injections des données"
    ]
  },
  {
    "objectID": "itgr_db_injections_rlavoie.html#étape-dinjections-des-données",
    "href": "itgr_db_injections_rlavoie.html#étape-dinjections-des-données",
    "title": "Injections des données",
    "section": "Étape d’injections des données",
    "text": "Étape d’injections des données\nAfin de respecter l’intégrité référentielle des données, l’injection des données doit se faire dans un certain ordre. Il faut par exemple renseigner en premier l’ensemble des sites avant de pouvoir déclarer les échantillons associés.\nVoici l’ordre d’injection attendu au regard de la structure de la base de données.\n\nSites\nSpecies\nProjects\nField samples\nLab samples\nAnalyte\nLab measurement\n\nL’ensemble des données destinés à populer les tables a été consolider lors des étapes précédentes. Nous allons maintenant procéder à leur importation dans la base de données.",
    "crumbs": [
      "Data integration [FR]",
      "Injections des données"
    ]
  },
  {
    "objectID": "itgr_db_injections_rlavoie.html#importation-des-données",
    "href": "itgr_db_injections_rlavoie.html#importation-des-données",
    "title": "Injections des données",
    "section": "Importation des données",
    "text": "Importation des données\n\nTable sites\n\nsites &lt;- readRDS(\"data/tbl_sites.rds\")\n\nOn tranforme les intitulées de colonnes du data.frame pour qu’ils correspondent à ceux de la table de données SQL.\n\ndata_sites &lt;- sites |&gt;\n    dplyr::select(\n        id_site = final_id,\n        province, \n        lat,\n        lon,\n        srid\n    )\n\nDBI::dbWriteTable(con, \"sites\", data_sites, append = TRUE)\n\n\n\nTable species\n\ndata_species &lt;- readRDS(\"data/tbl_species.rds\")\nDBI::dbWriteTable(con, \"species\", data_species, append = TRUE)\n\n\n\nTable field_sample\n\nmap_sites &lt;- readRDS(\"data/tbl_sites.rds\") |&gt;\n    tidyr::separate_rows(original_ids, sep = \";\") |&gt;\n    dplyr::select(original_ids, final_id)\n\noptions(dplyr.summarise.inform = FALSE)\n\nsamples &lt;- itgr_samples_info() |&gt;\n  dplyr::select(-received_date, -id_project, -source) |&gt;\n  dplyr::mutate(collection_date = as.character(collection_date)) |&gt;\n  # Ajout des identifiants de site consolidé\n  dplyr::left_join(map_sites, by = c(\"id_site\" = \"original_ids\")) |&gt;\n  dplyr::select(-id_site) |&gt;\n  dplyr::rename(id_site = final_id) |&gt;\n  dplyr::mutate_if(is.character, stringr::str_trim) |&gt;\n  dplyr::mutate_if(is.character, ~ifelse(.x == \"N/A\", NA, .x)) |&gt;\n  dplyr::mutate_if(is.character, ~ifelse(.x == \"NA\", NA, .x)) |&gt;  \n  dplyr::distinct() |&gt;\n  # Nettoyage des duplicates pour les champs age et tissus\n  dplyr::group_by(\n    dplyr::across(c(-age, -tissue))\n  ) |&gt; dplyr::summarise(\n    age = paste0(na.omit(age), collapse = \";\"),\n    tissue = paste0(na.omit(tissue), collapse = \";\")\n  ) |&gt; dplyr::ungroup() |&gt;\n  dplyr::mutate(\n    age = dplyr::na_if(age, \"\"),\n    tissue = dplyr::na_if(tissue, \"\")\n  ) |&gt; \n  # Nettoyage des sample IDs avec une dernière lettre\n  dplyr::mutate(id_lab_sample = stringr::str_replace(id_lab_sample, \"\\\\s\\\\w+$\", \"\")) |&gt;\n  dplyr::group_by(\n    dplyr::across(c(-id_lab_sample, -id_source_report))\n  ) |&gt; dplyr::summarise(\n    id_lab_sample = paste0(na.omit(id_lab_sample), collapse = \";\"),\n    id_source_report = paste0(na.omit(id_source_report), collapse = \";\")\n  ) |&gt; dplyr::ungroup() |&gt; \n  dplyr::distinct() |&gt; \n  dplyr::group_split(id_field_sample) |&gt;\n  # Création d'un identifiant unique d'échantillonnage en se basant sur la date de collection\n  # L'identifiant de certains échantillons n'est pas unique\n  purrr::map(\\(df){\n    if(nrow(df) &gt; 1){\n      df &lt;- df |&gt;\n        dplyr::mutate(id_field_sample = paste0(\n          id_field_sample, \"-\",\n          stringr::str_replace_all(collection_date, \"[-]\", \"\")\n        ))\n    }\n    return(df)\n  }) |&gt; dplyr::bind_rows() |&gt; \n  dplyr::group_by(id_field_sample) |&gt;\n  dplyr::mutate(id_field_sample = paste0(id_field_sample, \"-\", dplyr::row_number())) |&gt;\n  dplyr::ungroup()\n\n# Inject field samples\nDBI::dbWriteTable(con, \"field_sample\", dplyr::select(samples, -id_lab_sample, -id_source_report) |&gt; \n  dplyr::distinct(), append = TRUE)\n\n\n\nTable project\n\nproject_samples &lt;- itgr_samples_info()[,c(\"id_project\", \"id_source_report\")] |&gt; dplyr::distinct()\nprojects_reports &lt;- readRDS(\"data/tbl_projects_reports.rds\") \n\nprojects &lt;- dplyr::select(projects_reports, id_project = project_id, \n  title = project_title, investigator = project_leader) |&gt;\n  dplyr::mutate(organization = \"ECCC\", data_manager = NA, email_investigator = NA, email_data_manager = NA, description = NA) |&gt; \n  dplyr::group_by(id_project) |&gt;\n  dplyr::summarise(title = paste0(na.omit(unique(title)), collapse = \";\"), investigator = paste0(na.omit(unique(investigator)), collapse = \";\")) |&gt;\n  dplyr::mutate(title = dplyr::na_if(title, \"\"), investigator = dplyr::na_if(investigator, \"\")) |&gt;\n  dplyr::distinct()\n \nDBI::dbWriteTable(con, \"project\", projects, append = TRUE)\n\n\n\nTable report\n\nreports &lt;- projects_reports |&gt; \n  dplyr::select(id_project = project_id, id_report = report_id, report_date, report_access_path) |&gt;\n  dplyr::distinct() \n\nDBI::dbWriteTable(con, \"report\", reports, append = TRUE)\n\n\n\nTable lab_sample\n\nlab_sample &lt;- itgr_measurements() |&gt;\n  dplyr::select(id_lab_sample = SampleID) |&gt;\n  dplyr::distinct() \n\n\nDBI::dbWriteTable(con, \"lab_sample\", lab_sample, append = TRUE)\n\n\n\nTable lab_field_sample\n\nlab_field_samples &lt;- samples |&gt; \n  dplyr::select(id_lab_sample, id_field_sample, -id_source_report) |&gt;\n  tidyr::separate_longer_delim(id_lab_sample, delim = \";\") |&gt;\n  dplyr::distinct() \n\n## Add missing lab_sample\npresent_lab_sample_id &lt;- DBI::dbGetQuery(con, \"SELECT DISTINCT id_lab_sample FROM lab_sample;\")\n\nmissing_lab_sample &lt;- dplyr::select(lab_field_samples, id_lab_sample) |&gt;  \n  dplyr::distinct() |&gt;\n  dplyr::filter(!(id_lab_sample %in% present_lab_sample_id$id_lab_sample))\n\nDBI::dbWriteTable(con, \"lab_sample\", missing_lab_sample, append = TRUE)\n\n\nDBI::dbWriteTable(con, \"lab_field_sample\", lab_field_samples, append = TRUE)\n\n\n\nTable analytes\n\nanalytes &lt;- readRDS(\"data/tbl_analytes.rds\") |&gt;\n  dplyr::select(\n    id_analyte = final_id,\n    name,\n    other_name,\n    short_name,\n    unit = Units,\n    family = conpound_family,\n    casid,\n    pubcid,\n    is_dry_weight,\n    on_isolated_lipid,\n    note_analyte = notes\n  )\n\n\nDBI::dbWriteTable(con, \"analyte\", analytes, append = TRUE)\n\n\n\nTable lab_measurements\n\nanalytes_ref &lt;- readRDS(\"data/tbl_analytes.rds\") |&gt;\n  tidyr::separate_rows(original_ids, sep = \";\") |&gt;\n  dplyr::select(original_ids, final_id) |&gt;\n  dplyr::distinct()\n\nmeasurements &lt;- itgr_measurements() |&gt;\n    dplyr::mutate(\n        key = stringr::str_replace(variable, \"PCB-|PCB \", \"PCB\") |&gt;\n            janitor::make_clean_names(allow_dupes = TRUE, case = \"none\") |&gt; tolower()\n    ) |&gt; dplyr::left_join(analytes_ref, by = c(\"key\" = \"original_ids\")) |&gt;\n    dplyr::filter(conpound_family != \"SImean\")\n\npercent_moisture_lipid &lt;- dplyr::filter(measurements, final_id %in% c(\"plipid\", \"pmoisture\")) |&gt;\n  dplyr::select(-variable, -key) |&gt;\n  tidyr::pivot_wider(names_from = \"final_id\", values_from = \"value\")\n\nmeasurements &lt;- dplyr::filter(measurements, !final_id %in% c(\"plipid\", \"pmoisture\")) |&gt;\n  dplyr::left_join(percent_moisture_lipid) |&gt;\n  dplyr::filter(!is.na(value) & value != \"\" & value != \"NA\" & value != \"NDR\")\n\nmeasurements &lt;- measurements |&gt; dplyr::select(\n    id_analyte = final_id,\n    id_lab_sample = SampleID,\n    value,\n    percent_lipid = plipid,\n    percent_moisture = pmoisture\n  ) |&gt; \n  dplyr::mutate(id_lab_sample = stringr::str_replace(id_lab_sample, \"\\\\s\\\\w+$\", \"\")) |&gt;\n  dplyr::mutate(id_lab_sample = stringr::str_replace(id_lab_sample, \"[*]\", \"\")) \n\nmeasurements &lt;- measurements |&gt; \n  dplyr::mutate(is_censored = toxbox::detect_cens(value)) |&gt;\n  dplyr::mutate(value = toxbox::remove_cens(value)) |&gt;\n  dplyr::filter(!is.na(value))\n\n\nDBI::dbWriteTable(con, \"lab_measurement\", measurements, append = TRUE)",
    "crumbs": [
      "Data integration [FR]",
      "Injections des données"
    ]
  },
  {
    "objectID": "itgr_tbl_analytes.html",
    "href": "itgr_tbl_analytes.html",
    "title": "Consolidation de la nomenclature des analytes",
    "section": "",
    "text": "Nous désirons consolider la nomenclature des analytes. On peut observer plusieurs divergences dans la facon de nommer les analytes, exemple PCB-17 ou PCB 17. Cette section documente la démarche pour tendre vers une réconciliation des termes utilisés.\nOn charge les données intégrées depuis le package toxbox. Les données ne sont pas entreposées dans le package, la function itgr_measurements() permet de lire les fichiers Excels entreposées sur le disque réseau Z: et les fusionne dans un seul data.frame. Il faut pour cela que le VPN soit ouvert, si vous n’êtes pas directement sur le réseau d’environnement canada.\nsource(\"src/itgr_measurements.R\")\nmeasurements &lt;- itgr_measurements()",
    "crumbs": [
      "Data integration [FR]",
      "Consolidation de la nomenclature des analytes"
    ]
  },
  {
    "objectID": "itgr_tbl_analytes.html#analytes-avec-un-numéro-cas-fournis-par-le-laboratoire",
    "href": "itgr_tbl_analytes.html#analytes-avec-un-numéro-cas-fournis-par-le-laboratoire",
    "title": "Consolidation de la nomenclature des analytes",
    "section": "Analytes avec un numéro CAS fournis par le laboratoire",
    "text": "Analytes avec un numéro CAS fournis par le laboratoire\nLa nomenclature des composées chimiques / analytes peut diverger d’un laboratoire à un autre. Chaque pays dispose également de sa propre nomenclature (ex. États-Unis, Allemagne, Royaume-Unis). Afin de reconcilier la nomenclature, nous souhaitons utiliser un identifiant unique international tel que l’International Chemical Identifier (InChl).\nDans un premier temps, on charge les données sur les analytes (incluant le CAS) fournies par les laboratoires. Le fichier analytes_consolidation_27032024 est la fusion des onglets Analyte Information des différentes base de données. On fusionne les données sur les analytes avec les mesures.\n\nanalytes &lt;- readxl::read_excel(\"Z:/07-Données BD/intermediate_files/analytes_consolidation_27032024.xlsx\") |&gt;\n    dplyr::select(Analyte, CASNumber) |&gt;\n    dplyr::filter(!is.na(CASNumber)) |&gt;\n    dplyr::mutate(\n        key = janitor::make_clean_names(Analyte, allow_dupes = TRUE, case = \"none\") |&gt; tolower()\n    ) |&gt;\n    dplyr::distinct()\n\nmeasurements &lt;- measurements |&gt; \n    dplyr::mutate(\n        key = stringr::str_replace(variable, \"PCB-|PCB \", \"PCB\") |&gt;\n            janitor::make_clean_names(allow_dupes = TRUE, case = \"none\") |&gt; tolower()\n    )\n\nmeasurements &lt;-  measurements |&gt;\n    dplyr::left_join(analytes, by = \"key\")\n\nOn isole le nom des contaminants pour lesquels nous n’avons pas de CAS associés. Voici la liste de ces contaminants:\ncontaminants_orphelins &lt;- measurements |&gt; \n    dplyr::filter(is.na(CASNumber)) |&gt;\n    dplyr::select(key, variable, CASNumber) |&gt;\n    dplyr::distinct()\n\nreactable::reactable(contaminants_orphelins, searchable = TRUE)",
    "crumbs": [
      "Data integration [FR]",
      "Consolidation de la nomenclature des analytes"
    ]
  },
  {
    "objectID": "itgr_tbl_analytes.html#obtention-du-numéro-de-cas-par-le-service-cts",
    "href": "itgr_tbl_analytes.html#obtention-du-numéro-de-cas-par-le-service-cts",
    "title": "Consolidation de la nomenclature des analytes",
    "section": "Obtention du numéro de CAS par le service CTS",
    "text": "Obtention du numéro de CAS par le service CTS\nLa fonction webchem::cts_convert() permet d’interroger plusieurs base de données de référence sur des composées chimiques et d’extraire des identifiants tels que le CAS à partir du nom d’un composé chimique. La fonction webchem::cts_convert() s’interface sur le service https://cts.fiehnlab.ucdavis.edu/.\n\ncas_from_cts &lt;- webchem::cts_convert(contaminants_orphelins$variable, from = \"Chemical Name\", to = \"CAS\", match = \"first\")\n\ncas &lt;- purrr::map2_df(names(cas_from_cts), cas_from_cts, \\(n, c){\n    return(data.frame(variable = n, CASNumber = c))\n})\n\nreactable::reactable(cas, searchable = TRUE)\n\nEn cherchant le numéro CAS avec le nom du composé, on s’apercoit que plusieurs PCB (ex. PCB 60 et 64) tombent sous le même CAS, ce qui est incorrect. On change donc d’approche puisque le service CTS ne semblent pas être un bon service de résolution par le nom.",
    "crumbs": [
      "Data integration [FR]",
      "Consolidation de la nomenclature des analytes"
    ]
  },
  {
    "objectID": "itgr_tbl_analytes.html#obtention-du-numéro-de-cas-par-le-service-chemspider-csid",
    "href": "itgr_tbl_analytes.html#obtention-du-numéro-de-cas-par-le-service-chemspider-csid",
    "title": "Consolidation de la nomenclature des analytes",
    "section": "Obtention du numéro de CAS par le service ChemSpider (csid)",
    "text": "Obtention du numéro de CAS par le service ChemSpider (csid)\nCe service est fournis par la Société Royale de Chimie. C’est un des services qui semble être robuste pour obtenir un identifiant unique à partir du nom du composé. Une fois, l’identifiant ChemSpider obtenue il est possible d’obtenir le numéro CAS en utilisant le service https://cts.fiehnlab.ucdavis.edu/. On utilise ce service pour effectuer la conversion d’identifiants entre nomenclature (ex. csid vers CAS). Attention, ce service requière l’enregistrement d’un compte et le nombre de requête est limités à 1000 appels par mois.\n\ncsid &lt;- webchem::get_csid(contaminants_orphelins$variable, from = \"name\") \ncsid &lt;- csid |&gt; dplyr::rename(variable = query) |&gt; \n    dplyr::left_join(\n        dplyr::select(contaminants_orphelins, key, variable)\n    ) |&gt; \n    dplyr::filter(!is.na(csid)) |&gt;\n    dplyr::mutate(csid = as.character(csid))\nsaveRDS(csid, \"data/csid.rds\")\n\n\nif(!exists(\"csid\")) csid &lt;- readRDS(\"data/csid.rds\")\n\ncas_from_csid &lt;- webchem::cts_convert(csid$csid, from = \"ChemSpider\", to = \"CAS\", match = \"first\")\n\ncas2 &lt;- purrr::map2_df(names(cas_from_csid), cas_from_csid, \\(n, c){\n        return(data.frame(csid = n, CASNumber = c))\n    }) |&gt; dplyr::left_join(csid, by = \"csid\")\n\nreactable::reactable(cas2, searchable = TRUE)\n\nEffectuer la résolution de la nomenclature des composées par l’utilisation du service ChemSpider semble plus prometteur. Après une vérification visuelle, on voit que les composées ne présentent plus d’identifiant unique identique.",
    "crumbs": [
      "Data integration [FR]",
      "Consolidation de la nomenclature des analytes"
    ]
  },
  {
    "objectID": "itgr_tbl_analytes.html#ajout-de-lidentifiant-pubchem-pubcid",
    "href": "itgr_tbl_analytes.html#ajout-de-lidentifiant-pubchem-pubcid",
    "title": "Consolidation de la nomenclature des analytes",
    "section": "Ajout de l’identifiant PubChem (pubcid)",
    "text": "Ajout de l’identifiant PubChem (pubcid)\nAfin de permettre le retrait d’informations supplémentaires sur les composées chimiques, une des base de données d’intérêt est PubChem. À partir de cette base de données, on peut effectuer le retrait de certaines propriétés chimiques du composée telles que la masse moléculaire par exemple.\n\npubcid &lt;- webchem::cts_convert(cas2$csid, from = \"ChemSpider\", to = \"PubChem CID\", match = \"first\")\n\ncas3 &lt;- purrr::map2_df(names(pubcid), pubcid, \\(n, c){\n        return(data.frame(csid = n, pubcid = c))\n    }) |&gt; dplyr::distinct() |&gt; \n        dplyr::left_join(cas2, by = \"csid\") |&gt; \n        dplyr::distinct() |&gt;\n        # On consolide le tableau final\n        dplyr::rename(casid = CASNumber) |&gt;\n        dplyr::mutate(variable = tolower(variable)) |&gt;\n        dplyr::distinct()",
    "crumbs": [
      "Data integration [FR]",
      "Consolidation de la nomenclature des analytes"
    ]
  },
  {
    "objectID": "itgr_tbl_analytes.html#consolidation-de-la-table-de-reference-des-analytes",
    "href": "itgr_tbl_analytes.html#consolidation-de-la-table-de-reference-des-analytes",
    "title": "Consolidation de la nomenclature des analytes",
    "section": "Consolidation de la table de reference des analytes",
    "text": "Consolidation de la table de reference des analytes\nOn a ajouté 3 identifiants pour chaque composée chimique de la base de données. Parmis, ces identifiants nous retrouvons: le CAS (casid, identifiant fournis généralement par le laboratoire d’analyse, nomenclature américaine), le ChemSpider ID (csid, nomenclature britanique) et enfin le PubChem ID (pubcid, nomenclature américaine).\nOn a enfin toutes les informations pour construire la table de référence des composées chimiques. On récupère les composées chimiques pour lesquelles le CAS est renseigné par le laboratoire.\n\ncontaminants_with_cas &lt;- measurements |&gt; \n    dplyr::filter(!is.na(CASNumber)) |&gt;\n    dplyr::select(key, variable, CASNumber) |&gt;\n    dplyr::rename(casid = CASNumber) |&gt;\n    dplyr::mutate(variable = tolower(variable)) |&gt;\n    dplyr::distinct()\n\nOn va chercher le PubChem ID et et le spiderChem ID pour les contaminants qui avaient déjà un CAS (fournit par le laboratoire).\n\ncsid &lt;- webchem::cts_convert(contaminants_with_cas$casid, from = \"CAS\", to = \"ChemSpider\", match = \"first\")\ncsid &lt;- purrr::map2_df(names(csid), csid, \\(n, c){\n        return(data.frame(casid = n, csid = c))\n    })\n\npubcid &lt;- webchem::cts_convert(contaminants_with_cas$casid, from = \"CAS\", to = \"PubChem CID\", match = \"first\")\npubcid &lt;- purrr::map2_df(names(pubcid), pubcid, \\(n, c){\n        return(data.frame(casid = n, pubcid = c))\n    })\n\ncontaminants &lt;- contaminants_with_cas |&gt; \n    dplyr::left_join(csid, by = \"casid\") |&gt;\n    dplyr::left_join(pubcid, by = \"casid\") |&gt;\n    dplyr::distinct() |&gt;\n    dplyr::bind_rows(cas3) |&gt;\n    dplyr::mutate(\n        url_casid = ifelse(!is.na(casid), paste0(\"https://commonchemistry.cas.org/detail?cas_rn=\", casid), NA),\n        url_pubcid = ifelse(!is.na(pubcid), paste0(\"https://pubchem.ncbi.nlm.nih.gov/compound/\", pubcid), NA),\n        url_csid = ifelse(!is.na(csid), paste0(\"https://www.chemspider.com/Chemical-Structure.\", csid, \".html\"), NA)\n    ) |&gt;\n    dplyr::select(-variable) |&gt;\n    dplyr::distinct()\n\nValidation: Est-ce que tous les contaminants dans la table de référence sont présent dans la table des mesures?\n\nkeys &lt;- measurements$key |&gt;\n    unique()\n\ncontaminants_without_ids &lt;- data.frame(key = keys[!keys %in% contaminants$key], pubcid = NA, csid = NA, casid = NA)\n\ncontaminants &lt;- dplyr::bind_rows(contaminants, contaminants_without_ids) |&gt;\n    dplyr::distinct()\n\nsources &lt;- dplyr::select(measurements, key, source, conpound_family) |&gt; \n    dplyr::distinct()\n\nOn écrit le fichier pour pouvoir repasser manuellement dessus.\n\nwritexl::write_xlsx(list(contaminants, sources), path = \"data/tbl_contaminants_ref.xlsx\")\n\n\nAjout des unités à la table de référence\nOn utilise les données contenues dans le fichier Z:/07-Données BD/intermediate_files/analytes_consolidation_27032024.xlsx et qui contient les unités pour un certains nombres de composées. Ce tableau est une fusion des informations documentés dans l’onglet “Analytes informations” des bases de données COEI, HERG et GBHE.\n\ntbl_analytes &lt;- readxl::read_excel(\"data/tbl_contaminants_ref_manual.xlsx\") |&gt;\n    tidyr::separate_rows(original_ids, sep = \";\")\n\nanalytes_units &lt;- readxl::read_excel(\"Z:/07-Données BD/intermediate_files/analytes_consolidation_27032024.xlsx\") |&gt;\n    dplyr::mutate(\n        key = janitor::make_clean_names(Analyte, allow_dupes = TRUE, case = \"none\") |&gt; tolower()\n    ) |&gt;\n    dplyr::select(key, Units) |&gt;\n    dplyr::distinct()\n\ntbl_analytes &lt;- tbl_analytes |&gt; dplyr::left_join(analytes_info, by = c(\"original_ids\" = \"key\")) |&gt; \n    dplyr::group_by_at(dplyr::vars(-original_ids, -Units)) |&gt;\n    dplyr::summarize(original_ids = paste(original_ids, collapse = \";\"), Units = paste(Units, collapse = \";\"))\n\nwritexl::write_xlsx(tbl_analytes, path = \"data/tbl_contaminants_ref.xlsx\")",
    "crumbs": [
      "Data integration [FR]",
      "Consolidation de la nomenclature des analytes"
    ]
  },
  {
    "objectID": "itgr_tbl_projects.html",
    "href": "itgr_tbl_projects.html",
    "title": "Recensement des projets",
    "section": "",
    "text": "Chaque rapport de laboratoire contient sur sa page de garde l’ensemble des métadonnées en lien avec le projet de recherche pour lequel cette analyse a été demandé. On désire donc extraire la page de garde de chacun des rapports de laboratoires afin d’obtenir la liste des projets.\nUn rapport de laboratoire peut être detectable dans une liste de fichier par la structure de son identifiant unique. Voici un exemple d’identifiant unique: CHEM-PCDD-00-07 ou encore MB-05-10. Ces identifiants ont une structure unique que l’on peut detecter grace à l’expression régulière suivante:\n\nregex_report_id &lt;- \"([A-Za-z]{2,5}-)?[A-Za-z]{2,5}-\\\\d{2}-\\\\d{2}\"\n\nLa variable regex_report_id sera utilisée plusieurs fois dans ce document.\nOn liste les rapports de laboratoire présents dans le dossier 03-Labo/Results Reports.\n\nreports_path &lt;- list.files(\n    \"C:/Users/VissaultS/Documents/03-Labo/Results Reports\", \n    pattern = \"*.pdf|*.docx|*.doc\", recursive = TRUE, full.names = TRUE\n)\n\n# On extrait les identifiants des rapports du nom du fichier\nreport_id &lt;- stringr::str_extract(reports_path, regex_report_id)\n\n# On obtient la signature du fichier, ca va être pratique pour detecter les fichiers dupliqués même si le nom du fichier est différent.\nfile_hash &lt;- tools::md5sum(reports_path)\n\n# On extrait l'extension du fichier\nfile_ext &lt;- reports_path |&gt; \n    strsplit(\"[.]\") |&gt; \n    purrr::map_chr(\\(e) return(e[2]))\n\n# On compose un tableau avec l'ensemble de ces informations\nreports &lt;- data.frame(\n        path = reports_path, \n        id = report_id, \n        hash = file_hash, \n        ext = file_ext\n    ) |&gt; tibble::as_tibble()\n\nNote: tools::md5sum permet de générer une signature unique propre au fichier. Ainsi deux fichiers identiques dans le contenu mais avec des noms différents pourront être identifié comme des duplicats.\nVoici la liste des fichiers identiques dans le dossier 03-Labo/Results Reports.\nreports_dup &lt;- reports |&gt; \n    tibble::as_tibble() |&gt;\n    janitor::get_dupes(-c(path)) |&gt;\n    dplyr::select(-hash)\n\nreports_dup |&gt; knitr::kable()\n\n\n\n\n\n\n\n\n\nid\next\ndupe_count\npath\n\n\n\n\nBMK-PFC-23-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/BMK-PFC-23-10_HERG-COEI_eggs2023.pdf\n\n\nBMK-PFC-23-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/EideràDuvet Rapports 1972-2023/BMK-PFC-23-10_HERG-COEI_eggs2023.pdf\n\n\nBMK-PFC-23-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/BMK-PFC-23-10_HERG-COEI_eggs2023.pdf\n\n\nCHEM-OC-22-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/CHEM-OC-22-10_GBHE-HERG2022.pdf\n\n\nCHEM-OC-22-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/CHEM-OC-22-10_GBHE-HERG2022.pdf\n\n\nCHEM-OC-22-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GrandHeron Rapports xxxx-2022/Rapports/CHEM-OC-22-10_GBHE-HERG2022.pdf\n\n\nMET-THg-22-05\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/MET-THg-22-05 - RALA01-2022_HERG-GBHEegg2022.pdf\n\n\nMET-THg-22-05\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GrandHeron Rapports xxxx-2022/Rapports/MET-THg-22-05 - RALA01-2022_HERG-GBHEegg2022.pdf\n\n\nMET-THg-22-05\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/MET-THg-22-05 - RALA01-2022_HERG-GBHEegg2022.pdf\n\n\nMET-THg-23-13\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/EideràDuvet Rapports 1972-2023/MET-THg-23-13 - RALA01-2023.pdf\n\n\nMET-THg-23-13\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/MET-THg-23-13 - RALA01-2023.pdf\n\n\nMET-THg-23-13\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/MET-THg-23-13 - RALA01-2023_OeufsCOEI-HERG2023.pdf\n\n\nTP-SI-22-09\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/TP-SI-22-09C_RALA01-2022_HERG-GBHEeggs2022.pdf\n\n\nTP-SI-22-09\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GrandHeron Rapports xxxx-2022/Rapports/TP-SI-22-09C_RALA01-2022_HERG-GBHEeggs2022.pdf\n\n\nTP-SI-22-09\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/TP-SI-22-09C_RALA01-2022_HERG-GBHEeggs2022.pdf\n\n\nCHEM-OC-21-08\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/CHEM-OC-21-08R.pdf\n\n\nCHEM-OC-21-08\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/FouBassan Rapports 1984-2019/CHEM-OC-21-08R.pdf\n\n\nCHEM-OC-22-05\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/CHEM-OC-22-05_HERGDeslauriers.pdf\n\n\nCHEM-OC-22-05\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/CHEM-OC-22-05_HERGDeslauriers.pdf\n\n\nCHEM-OC-23-08\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/CHEM-OC-23-08_EggHERG_COEI_2023.pdf\n\n\nCHEM-OC-23-08\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/EideràDuvet Rapports 1972-2023/CHEM-OC-23-08_EggHERG_COEI_2023.pdf\n\n\nMET-THg-21-03\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/FouBassan Rapports 1984-2019/MET-THg-21-03.pdf\n\n\nMET-THg-21-03\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/MET-THg-21-03 - RALA01-2021_eggs.pdf\n\n\nTP-SI-21-05\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/FouBassan Rapports 1984-2019/TP-SI-21-05C.pdf\n\n\nTP-SI-21-05\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/TP-SI-21-05C_RALA01-2021.pdf\n\n\n\nOn selectionne le premier rapport en se basant sur le id (ex. BMK-PFC-23-01) pour éliminer les rapports dupliqués pour la suite de l’analyse. On s’assure de selectionner préférablement les pdfs si on dispose d’un docx et d’un document pdf pour le même identifiant de rapport de laboratoire.\n\nreports &lt;- reports |&gt; \n    # On retire les rapports qui sont dupliqués\n    dplyr::group_by(hash) |&gt;\n    dplyr::slice(1) |&gt;\n    dplyr::ungroup() |&gt;\n    # Si plusieurs extension de fichiers, on selectionne ceux en PDF préférablement, sinon .docx, sinon .doc en dernier recours.\n    dplyr::group_split(id) |&gt;\n    purrr::map(\\(g){\n        g |&gt; dplyr::arrange(factor(ext, levels = c('pdf', 'docx', 'doc'))) |&gt;\n        dplyr::slice(1)\n    }) |&gt;\n    dplyr::bind_rows()\n\nQuelques rapports de laboratoire demeurent au format doc et docx.\ndocs &lt;- reports |&gt; dplyr::filter(ext %in% c('doc', 'docx')) \ndocs |&gt; knitr::kable()\n\n\n\npath\nid\nhash\next\n\n\n\n\n\nAfin de faciliter l’extraction des métadonnées par programmation, on convertit les fichiers .doc et .docx en pdf.",
    "crumbs": [
      "Data integration [FR]",
      "Recensement des projets"
    ]
  },
  {
    "objectID": "itgr_tbl_projects.html#établir-une-liste-des-projets",
    "href": "itgr_tbl_projects.html#établir-une-liste-des-projets",
    "title": "Recensement des projets",
    "section": "",
    "text": "Chaque rapport de laboratoire contient sur sa page de garde l’ensemble des métadonnées en lien avec le projet de recherche pour lequel cette analyse a été demandé. On désire donc extraire la page de garde de chacun des rapports de laboratoires afin d’obtenir la liste des projets.\nUn rapport de laboratoire peut être detectable dans une liste de fichier par la structure de son identifiant unique. Voici un exemple d’identifiant unique: CHEM-PCDD-00-07 ou encore MB-05-10. Ces identifiants ont une structure unique que l’on peut detecter grace à l’expression régulière suivante:\n\nregex_report_id &lt;- \"([A-Za-z]{2,5}-)?[A-Za-z]{2,5}-\\\\d{2}-\\\\d{2}\"\n\nLa variable regex_report_id sera utilisée plusieurs fois dans ce document.\nOn liste les rapports de laboratoire présents dans le dossier 03-Labo/Results Reports.\n\nreports_path &lt;- list.files(\n    \"C:/Users/VissaultS/Documents/03-Labo/Results Reports\", \n    pattern = \"*.pdf|*.docx|*.doc\", recursive = TRUE, full.names = TRUE\n)\n\n# On extrait les identifiants des rapports du nom du fichier\nreport_id &lt;- stringr::str_extract(reports_path, regex_report_id)\n\n# On obtient la signature du fichier, ca va être pratique pour detecter les fichiers dupliqués même si le nom du fichier est différent.\nfile_hash &lt;- tools::md5sum(reports_path)\n\n# On extrait l'extension du fichier\nfile_ext &lt;- reports_path |&gt; \n    strsplit(\"[.]\") |&gt; \n    purrr::map_chr(\\(e) return(e[2]))\n\n# On compose un tableau avec l'ensemble de ces informations\nreports &lt;- data.frame(\n        path = reports_path, \n        id = report_id, \n        hash = file_hash, \n        ext = file_ext\n    ) |&gt; tibble::as_tibble()\n\nNote: tools::md5sum permet de générer une signature unique propre au fichier. Ainsi deux fichiers identiques dans le contenu mais avec des noms différents pourront être identifié comme des duplicats.\nVoici la liste des fichiers identiques dans le dossier 03-Labo/Results Reports.\nreports_dup &lt;- reports |&gt; \n    tibble::as_tibble() |&gt;\n    janitor::get_dupes(-c(path)) |&gt;\n    dplyr::select(-hash)\n\nreports_dup |&gt; knitr::kable()\n\n\n\n\n\n\n\n\n\nid\next\ndupe_count\npath\n\n\n\n\nBMK-PFC-23-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/BMK-PFC-23-10_HERG-COEI_eggs2023.pdf\n\n\nBMK-PFC-23-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/EideràDuvet Rapports 1972-2023/BMK-PFC-23-10_HERG-COEI_eggs2023.pdf\n\n\nBMK-PFC-23-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/BMK-PFC-23-10_HERG-COEI_eggs2023.pdf\n\n\nCHEM-OC-22-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/CHEM-OC-22-10_GBHE-HERG2022.pdf\n\n\nCHEM-OC-22-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/CHEM-OC-22-10_GBHE-HERG2022.pdf\n\n\nCHEM-OC-22-10\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GrandHeron Rapports xxxx-2022/Rapports/CHEM-OC-22-10_GBHE-HERG2022.pdf\n\n\nMET-THg-22-05\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/MET-THg-22-05 - RALA01-2022_HERG-GBHEegg2022.pdf\n\n\nMET-THg-22-05\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GrandHeron Rapports xxxx-2022/Rapports/MET-THg-22-05 - RALA01-2022_HERG-GBHEegg2022.pdf\n\n\nMET-THg-22-05\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/MET-THg-22-05 - RALA01-2022_HERG-GBHEegg2022.pdf\n\n\nMET-THg-23-13\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/EideràDuvet Rapports 1972-2023/MET-THg-23-13 - RALA01-2023.pdf\n\n\nMET-THg-23-13\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/MET-THg-23-13 - RALA01-2023.pdf\n\n\nMET-THg-23-13\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/MET-THg-23-13 - RALA01-2023_OeufsCOEI-HERG2023.pdf\n\n\nTP-SI-22-09\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/TP-SI-22-09C_RALA01-2022_HERG-GBHEeggs2022.pdf\n\n\nTP-SI-22-09\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GrandHeron Rapports xxxx-2022/Rapports/TP-SI-22-09C_RALA01-2022_HERG-GBHEeggs2022.pdf\n\n\nTP-SI-22-09\npdf\n3\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/TP-SI-22-09C_RALA01-2022_HERG-GBHEeggs2022.pdf\n\n\nCHEM-OC-21-08\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/CHEM-OC-21-08R.pdf\n\n\nCHEM-OC-21-08\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/FouBassan Rapports 1984-2019/CHEM-OC-21-08R.pdf\n\n\nCHEM-OC-22-05\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/CHEM-OC-22-05_HERGDeslauriers.pdf\n\n\nCHEM-OC-22-05\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/GoelandArgente 2017, 2022-23/CHEM-OC-22-05_HERGDeslauriers.pdf\n\n\nCHEM-OC-23-08\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/CHEM-OC-23-08_EggHERG_COEI_2023.pdf\n\n\nCHEM-OC-23-08\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/EideràDuvet Rapports 1972-2023/CHEM-OC-23-08_EggHERG_COEI_2023.pdf\n\n\nMET-THg-21-03\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/FouBassan Rapports 1984-2019/MET-THg-21-03.pdf\n\n\nMET-THg-21-03\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/MET-THg-21-03 - RALA01-2021_eggs.pdf\n\n\nTP-SI-21-05\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/FouBassan Rapports 1984-2019/TP-SI-21-05C.pdf\n\n\nTP-SI-21-05\npdf\n2\nC:/Users/VissaultS/Documents/03-Labo/Results Reports/TP-SI-21-05C_RALA01-2021.pdf\n\n\n\nOn selectionne le premier rapport en se basant sur le id (ex. BMK-PFC-23-01) pour éliminer les rapports dupliqués pour la suite de l’analyse. On s’assure de selectionner préférablement les pdfs si on dispose d’un docx et d’un document pdf pour le même identifiant de rapport de laboratoire.\n\nreports &lt;- reports |&gt; \n    # On retire les rapports qui sont dupliqués\n    dplyr::group_by(hash) |&gt;\n    dplyr::slice(1) |&gt;\n    dplyr::ungroup() |&gt;\n    # Si plusieurs extension de fichiers, on selectionne ceux en PDF préférablement, sinon .docx, sinon .doc en dernier recours.\n    dplyr::group_split(id) |&gt;\n    purrr::map(\\(g){\n        g |&gt; dplyr::arrange(factor(ext, levels = c('pdf', 'docx', 'doc'))) |&gt;\n        dplyr::slice(1)\n    }) |&gt;\n    dplyr::bind_rows()\n\nQuelques rapports de laboratoire demeurent au format doc et docx.\ndocs &lt;- reports |&gt; dplyr::filter(ext %in% c('doc', 'docx')) \ndocs |&gt; knitr::kable()\n\n\n\npath\nid\nhash\next\n\n\n\n\n\nAfin de faciliter l’extraction des métadonnées par programmation, on convertit les fichiers .doc et .docx en pdf.",
    "crumbs": [
      "Data integration [FR]",
      "Recensement des projets"
    ]
  },
  {
    "objectID": "itgr_tbl_projects.html#convertion-des-documents-word-en-pdf",
    "href": "itgr_tbl_projects.html#convertion-des-documents-word-en-pdf",
    "title": "Recensement des projets",
    "section": "Convertion des documents Word en pdf",
    "text": "Convertion des documents Word en pdf\nCette étape a été complété manuellement.",
    "crumbs": [
      "Data integration [FR]",
      "Recensement des projets"
    ]
  },
  {
    "objectID": "itgr_tbl_projects.html#extraire-les-métadonnées-du-rapport",
    "href": "itgr_tbl_projects.html#extraire-les-métadonnées-du-rapport",
    "title": "Recensement des projets",
    "section": "Extraire les métadonnées du rapport",
    "text": "Extraire les métadonnées du rapport\nNous souhaitons générer une liste de tous les projets basée sur les 71 rapports de laboratoire stockés dans le dossier 03-Labo/Comptes rendus de résultats. La première page de chaque rapport de laboratoire contient toutes les informations pertinentes pour produire cette liste.\nPour chaque rapport, nous vérifions s’il s’agit d’une image ou non. Si le rapport est une image, nous devons utiliser une reconnaissance optique de caractères (OCR) afin d’extraire le texte de la première page et d’obtenir toutes les métadonnées pertinentes. Si c’est un pdf ou un fichier word, nous importons la première page du document.\n\n# On détect si le document est une image\nreports &lt;- reports |&gt; dplyr::mutate(\n    filename = basename(path),\n    is_image = purrr::map2_lgl(path, ext, \\(p, e) {\n        if(e == \"pdf\"){\n            out &lt;- pdftools::pdf_text(p)\n            !all(nchar(out) &gt; 15)\n        } else {\n            FALSE\n        }\n    })\n)\n\n# On extrait le texte par OCR si c'est une image\nfrontpages &lt;- purrr::map2_vec(reports$path, reports$is_image, \\(p, i) {\n        ifelse(isTRUE(i), \n            pdftools::pdf_ocr_text(pdf = p, pages = 1),\n            pdftools::pdf_text(pdf = p)[[1]]\n        )\n    }) |&gt; tolower()\n\nUne fois le texte de la première page isolé, on applique une série d’opération d’extractions de texte à partir de la position de mots clés. On isole ainsi le titre du projet, l’ID du projet, la date etc.\n\nproject_id &lt;- purrr::map_vec(frontpages, \\(f){\n    stringr::str_extract(f, \"(?&lt;=(project: |project |projects|projet :)).*(?=\\n)\")\n}) |&gt; \n    toupper() |&gt; \n    stringr::word(1) |&gt; \n    stringr::str_replace_all(\"[.,]\", \"\") |&gt;\n    stringr::str_trim() |&gt;\n    dplyr::na_if(\"\")\n\nproject_leader &lt;- purrr::map_vec(frontpages, \\(f){\n        stringr::str_extract(f, \"(?&lt;=(project leader: |project leader |project manager: |manager: |study leader: |nom du requérant :)).*(?=\\n)\")\n    }) |&gt; \n    stringr::str_replace_all(c(\"[_|:]\" = \"\", \"[:digit:]\" = \"\", \"[.]$\" = \"\")) |&gt; \n    stringr::str_to_title() |&gt;\n    stringr::str_trim()\n\nproject_dates &lt;- frontpages |&gt;\n    purrr::map_vec(\\(f){\n        dates &lt;- stringr::str_extract(f, \"\\\\d{4}-\\\\d{2}-\\\\d{2}\")\n        if(is.na(dates)) {\n            dates &lt;- stringr::str_extract(f, \"(?&lt;=(date: )).*(?=\\n)\")\n        }\n        return(dates)\n    }) \n        \nreportsProject &lt;- data.frame(\n    report_id = reports$id, \n    report_access_path = stringr::str_replace_all(reports$path, \"C:/Users/VissaultS/Documents\", \"Z:\"), \n    project_id, project_leader, project_dates, project_title = NA\n)\n\nLe data.frame reportsProject est à la base du fichier “Z:\\07-Données BD_projects_list_extract_25032024.xlsx”.",
    "crumbs": [
      "Data integration [FR]",
      "Recensement des projets"
    ]
  },
  {
    "objectID": "itgr_tbl_projects.html#valider-lexistence-de-rapports-de-laboratoire-dans-le-dossier-01-projet-et-suivis",
    "href": "itgr_tbl_projects.html#valider-lexistence-de-rapports-de-laboratoire-dans-le-dossier-01-projet-et-suivis",
    "title": "Recensement des projets",
    "section": "Valider l’existence de rapports de laboratoire dans le dossier 01-Projet et suivis",
    "text": "Valider l’existence de rapports de laboratoire dans le dossier 01-Projet et suivis\nOn valide si certains de ces rapports ne se retrouvent pas dans le dossier 03-Labo/Comptes rendus. Ces rapports pourraient potentiellement nous interressés.\n\nfiles &lt;- list.files(\n    \"C:/Users/VissaultS/Documents/01-Projets et suivis\", \n    pattern = \"*.pdf|*.docx|*.doc\", recursive = TRUE, full.names = TRUE\n)\n\npotential_reports &lt;- data.frame(file = files[which(stringr::str_detect(files, regex_report_id))])\n\npotential_reports &lt;- potential_reports |&gt; dplyr::mutate(\n    id = stringr::str_extract(file, regex_report_id) |&gt; toupper(),\n    in_lab_report_folder = !(id %in% reports$id)\n) |&gt; dplyr::arrange(in_lab_report_folder) |&gt;\n    dplyr::mutate(file = stringr::str_replace(file, \"C:/Users/VissaultS/Documents/\", \"Z:\"))",
    "crumbs": [
      "Data integration [FR]",
      "Recensement des projets"
    ]
  }
]